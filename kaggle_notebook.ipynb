{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52fa1ed8",
   "metadata": {},
   "source": [
    "# üå∏ Tanit Multimodal Fertility Assistant\n",
    "### Production-Ready AI Companion for Fertility Care\n",
    "\n",
    "**Features:**\n",
    "- üé§ Voice input (faster-whisper STT)\n",
    "- üì∏ Image understanding (Qwen2-VL)\n",
    "- üß† Medical knowledge grounding (GraphRAG)\n",
    "- üí¨ Empathetic responses (Qwen2.5-LLM)\n",
    "\n",
    "**Setup time:** 15-20 minutes (first run downloads models)\n",
    "\n",
    "**GPU Required:** P100 or T4 (enable in settings ‚û°Ô∏è Accelerator ‚û°Ô∏è GPU P100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6628fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/AyaSaadawi/tanit-fertility-assistant.git\n",
    "%cd tanit-fertility-assistant\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6b212",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "This installs all required Python packages (~5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c799377",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import gradio as gr\n",
    "import transformers\n",
    "\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ Gradio: {gr.__version__}\")\n",
    "print(f\"‚úÖ Transformers: {transformers.__version__}\")\n",
    "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6a939",
   "metadata": {},
   "source": [
    "## Building GraphRAG Knowledge Base\n",
    "\n",
    "Creates medical knowledge graph from fertility guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1971ed6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python rag/graphrag_builder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2db15",
   "metadata": {},
   "source": [
    "## Testing Components Individually\n",
    "\n",
    "### Test GraphRAG Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3669149",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from rag.graphrag_query import GraphRAGEngine\n",
    "\n",
    "# Initialize GraphRAG\n",
    "graphrag = GraphRAGEngine(index_path=\"rag/graphrag_index\")\n",
    "\n",
    "# Test query\n",
    "result = graphrag.query(\"What does AMH level mean for fertility?\")\n",
    "\n",
    "print(\"\\nüìö GraphRAG Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(result['formatted_context'])\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úÖ Retrieved {len(result['nodes'])} knowledge nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e638e72",
   "metadata": {},
   "source": [
    "### Test Safety Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1b33b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from utils.safety import SafetyGuardrails\n",
    "\n",
    "safety = SafetyGuardrails()\n",
    "\n",
    "# Test system prompt\n",
    "print(\"üõ°Ô∏è Medical System Prompt:\")\n",
    "print(\"=\" * 60)\n",
    "print(safety.get_medical_system_prompt()[:500] + \"...\")\n",
    "\n",
    "# Test disclaimer\n",
    "print(\"\\nüí° Sample Disclaimer:\")\n",
    "print(\"=\" * 60)\n",
    "sample_response = \"Your AMH level is slightly low.\"\n",
    "with_disclaimer = safety.apply_disclaimers(sample_response, \"fertility\")\n",
    "print(with_disclaimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5c4b3",
   "metadata": {},
   "source": [
    "## Launch Mode Options\n",
    "\n",
    "### Option A: Demo Mode (Instant - Recommended First)\n",
    "\n",
    "Launches instantly with mock AI responses. Perfect for:\n",
    "- Testing UI immediately\n",
    "- Recording demo video\n",
    "- Showing functionality without waiting\n",
    "\n",
    "**No model downloads required!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e13b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Launches instantly with mock AI responses\n",
    "# Perfect for testing UI and recording demo video\n",
    "!python app_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581a5e8",
   "metadata": {},
   "source": [
    "### Option B: Production Mode (Real AI Models)\n",
    "\n",
    "‚ö†Ô∏è **Warning:** First run downloads ~10GB of models (10-15 minutes)\n",
    "\n",
    "**Only run this if:**\n",
    "- ‚úÖ You have GPU enabled (P100 or T4)\n",
    "- ‚úÖ You have 10-15 minutes to wait\n",
    "- ‚úÖ You want real AI model inference\n",
    "\n",
    "**After first run, subsequent launches take only 30 seconds (models are cached)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829da94c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download and run real AI models\n",
    "# This takes 10-15 minutes on first run\n",
    "# Subsequent runs: 30 seconds (cached)\n",
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5591662",
   "metadata": {},
   "source": [
    "## Accessing the Application\n",
    "\n",
    "After running either Option A (demo) or B (production) above, you'll see output like:\n",
    "```\n",
    "Running on local URL:  http://127.0.0.1:7860\n",
    "Running on public URL: https://xxxxx.gradio.live\n",
    "```\n",
    "\n",
    "**Click the public URL** (https://xxxxx.gradio.live) to access the application!\n",
    "\n",
    "### Try These Queries:\n",
    "\n",
    "1. **Text:** \"What does an AMH of 1.5 ng/mL mean at age 32?\"\n",
    "2. **Voice:** Record \"I'm 34, my AMH is 1.1, should I be worried?\"\n",
    "3. **Image:** Upload a hormone panel screenshot\n",
    "4. **Combined:** Voice + Image for complete multimodal interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6100e",
   "metadata": {},
   "source": [
    "## üé• Recording Your Demo Video\n",
    "\n",
    "**Recommended workflow:**\n",
    "\n",
    "1. Run Cell 12 (`app_demo.py`) for instant launch\n",
    "2. Open the **public Gradio URL** (https://xxxxx.gradio.live)\n",
    "3. Start screen recording (Loom/OBS)\n",
    "4. Show these 4 interactions:\n",
    "   - ‚úÖ Voice input about AMH levels\n",
    "   - ‚úÖ Image upload of lab results\n",
    "   - ‚úÖ Text query about PCOS\n",
    "   - ‚úÖ Complex multimodal query (voice + image)\n",
    "5. Explain architecture while demonstrating\n",
    "6. Stop recording (aim for 5-10 minutes)\n",
    "\n",
    "**Loom.com is perfect for this!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6a1cd",
   "metadata": {},
   "source": [
    "## üìä Performance Monitoring\n",
    "\n",
    "Check GPU usage and memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afe4c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"üíæ Memory Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"üíæ Max Memory Used: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Show memory breakdown\n",
    "    print(f\"\\nüìä GPU Memory Breakdown:\")\n",
    "    print(f\"   Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"   Used: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"   Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU available - enable GPU in Notebook Settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c52f2",
   "metadata": {},
   "source": [
    "## üêõ Troubleshooting\n",
    "\n",
    "### Issue: \"Knowledge base not found\"\n",
    "Run: `!python rag/graphrag_builder.py`\n",
    "\n",
    "### Issue: \"CUDA out of memory\"\n",
    "Solution 1: Use demo mode instead: `!python app_demo.py`\n",
    "Solution 2: Restart kernel and clear cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f213a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run this if you get CUDA out of memory errors\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear Python garbage\n",
    "gc.collect()\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úÖ GPU cache cleared\")\n",
    "    print(f\"üíæ Free memory: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa2422",
   "metadata": {},
   "source": [
    "## üìù Important Notes\n",
    "\n",
    "**Timing:**\n",
    "- **First run:** 10-15 minutes (model downloads)\n",
    "- **Subsequent runs:** 30 seconds (cached models)\n",
    "- **Demo mode:** Instant (no downloads)\n",
    "\n",
    "**Requirements:**\n",
    "- **GPU:** P100 or T4 (enable in settings)\n",
    "- **Storage:** 12GB for full models\n",
    "- **RAM:** 16GB recommended\n",
    "\n",
    "**Model Downloads (first run only):**\n",
    "- Qwen2-VL-2B-Instruct: ~5GB\n",
    "- Qwen2.5-3B-Instruct: ~3GB\n",
    "- faster-whisper-base: ~1GB\n",
    "- Total: ~10GB\n",
    "\n",
    "**After first run, all models are cached and app launches in 30 seconds!**\n",
    "\n",
    "---\n",
    "\n",
    "**Built for Tanit - Q2 2026 Patient-Facing Companion** üå∏\n",
    "\n",
    "**Repository:** https://github.com/AyaSaadawi/tanit-fertility-assistant"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
